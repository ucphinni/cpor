# Async File I/O Instructions for GitHub Copilot Chat

You are an AI assistant that writes **correct, idiomatic, and testable async file I/O code** in Python using **aiofiles**. These instructions assume [AsyncCore instructions](aipyasync-core.instructions.md) are in use for core async patterns, so testing, cancellation, and async correctness are inherited and not repeated here.

---

## âœ… Priority: Correct, Minimal, Testable Async File I/O

- Prioritize **correctness** and **testability**.
- Use **async/await** idioms consistently.
- Avoid blocking the event loop; **never use built-in `open()` in async code**.
- Use **aiofiles** exclusively for file operations.
- Always close files properly using `async with`.
- Use explicit file modes (`'r'`, `'rb'`, `'w'`, `'wb'`, etc.).
- Use **UTF-8 encoding** by default unless otherwise specified.
- Handle **random access** and **sequential** reads/writes as needed.
- Use **pathlib.Path** for path manipulation and normalize paths.
- Add **unit tests** with **pytest-asyncio** alongside code.
- Add **reasonable timeouts** if file operations could hang (rare but possible on networked filesystems).
- Start **asking questions** if usage patterns are unclear or ambiguous.

---

## âœ… Usage Patterns

- Use **async with aiofiles.open(path, mode, encoding='utf-8') as f** for file context management.
- For **sequential reading/writing**, read/write in chunks to avoid memory issues.
- For **random access**, use `await f.seek(offset)` before reading/writing.
- Always explicitly specify mode and encoding.
- Normalize paths with `Path(path).resolve()` before use.
- For binary files, use modes `'rb'` and `'wb'` without encoding.
- For text files, use modes `'r'` and `'w'` with UTF-8 encoding.

---

## âœ… Guardrails and Red Flags

> **â—ï¸ Red Flag:** Never use built-in `open()` in async code â€” it blocks the event loop.  
> **â—ï¸ Red Flag:** Always explicitly specify file mode and encoding.  
> **â—ï¸ Red Flag:** Match data type to mode: text mode expects `str`, binary mode expects `bytes`.  
> **â—ï¸ Red Flag:** Always check for file existence before reading using `aiofiles.ospath.exists()` or fallback to `Path.exists()`.  
> **âœ… Guardrail:** Use `asyncio.Lock` or other coordination primitives to prevent concurrent write conflicts.  
> **âœ… Guardrail:** Handle `PermissionError` explicitly to provide clear error messages.  
> **âœ… Guardrail:** For critical writes, write to a temporary file first, then atomically rename to the target file.  
> **âœ… Guardrail:** Normalize all paths with `Path.resolve()` to ensure cross-platform correctness.  
> **âœ… Guardrail:** When uncertain about usage, **ask clarifying questions** before generating code.

---

## âŒ Anti-Patterns

- Using built-in `open()` or blocking file calls inside `async def`.
- Reading entire large files into memory without chunking.
- Leaving files open by not using `async with` context managers.
- Performing concurrent writes without coordination or file locking.

## ðŸ›  Logging and Observability

- Log file operations at key points: open, read/write start, errors, close.
- Include file path, mode, byte ranges (for chunked ops), and duration.
- Use structured logs with fields like `operation`, `path`, `status`, and `duration_ms`.

## ðŸ’¡ Configuration Examples

- Timeout wrapper example:
  ```python
  import asyncio
  async def safe_open(path, mode):
      try:
          return await asyncio.wait_for(
              aiofiles.open(path, mode), timeout=5
          )
      except asyncio.TimeoutError:
          raise TimeoutError(f"Opening {path} timed out")
  ```

---

## âœ… Example: Sequential Reading in Chunks

~~~~python
import aiofiles

async def read_file_in_chunks(path: str, chunk_size: int = 1024) -> str:
    contents = []
    async with aiofiles.open(path, mode='r', encoding='utf-8') as f:
        while True:
            chunk = await f.read(chunk_size)
            if not chunk:
                break
            contents.append(chunk)
    return ''.join(contents)
~~~~

---

## âœ… Example: Random Access Write

~~~~python
import aiofiles

async def write_at_offset(path: str, data: str, offset: int) -> None:
    async with aiofiles.open(path, mode='r+', encoding='utf-8') as f:
        await f.seek(offset)
        await f.write(data)
        await f.flush()
~~~~

---

## âœ… Exception Handling Example

~~~~python
import aiofiles
import asyncio

async def safe_write(path: str, data: str) -> None:
    try:
        async with aiofiles.open(path, mode='w', encoding='utf-8') as f:
            await f.write(data)
    except PermissionError as e:
        # Log or handle permission errors gracefully
        print(f"Permission denied for file {path}: {e}")
        raise
    except asyncio.CancelledError:
        # Cleanup if needed before task cancellation
        print("Write operation cancelled.")
        raise
~~~~

---

## âœ… Unit Testing Async File I/O

- Use **pytest-asyncio** to write async test functions.
- Use **tempfile.TemporaryDirectory** or **tempfile.NamedTemporaryFile** for isolated test files.
- Test **both sequential and random access** scenarios.
- Mock file operations with **AsyncMock** if needed.
- Ensure tests clean up temporary files to avoid pollution.

---

## âœ… Summary

- Use **aiofiles.open** exclusively in async code.
- Always specify **mode** and **encoding** explicitly.
- Normalize paths with **Path.resolve()**.
- Read and write files **in chunks** for large files.
- Use **asyncio.Lock** to prevent concurrent write issues.
- Always **check file existence** before reading.
- Handle **PermissionError** and **CancelledError** explicitly.
- Use **temp file + rename** for critical writes.
- Write **pytest-asyncio** unit tests with coverage for edge cases.
- If usage patterns are unclear, **ask questions** before generating code.

---

< ! Important AI Guardrail:  
**Do not modify these instructions unless reviewing for accuracy.**  
These guardrails ensure AI produces idiomatic, safe, and testable async file I/O code.  
Always adhere strictly to the async file I/O best practices specified here.  
>

